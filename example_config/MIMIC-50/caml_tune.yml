# data
data_dir: data/MIMIC-50
data_name: MIMIC-50
min_vocab_freq: 3
max_seq_length: 2500

# train
seed: 1337
epochs: 200
batch_size: 16
optimizer: adam
learning_rate: ['grid_search', [0.001, 0.003, 0.0001, 0.0003]]
weight_decay: 0
patience: 10
shuffle: false

# eval
eval_batch_size: 1
monitor_metrics: ['Another-Macro-F1', 'Micro-F1','P@5']
val_metric: P@5

# model
model_name: CAML
init_weight: null
network_config:
  num_filter_per_size: ['grid_search', [50, 150, 250, 350, 450, 550]]
  filter_sizes: ['grid_search', [[2], [4], [6], [8], [10]]]
  dropout: ['grid_search', [0.2, 0.4, 0.6, 0.8]]
  activation: tanh

# pretrained vocab / embeddings
vocab_file: data/MIMIC-50/vocab.csv
embed_file: data/MIMIC-50/processed_full.embed
normalize_embed: true

# hyperparamter search
search_alg: basic_variant
embed_cache_dir: null
num_samples: 1

# other parameters specified in main.py::get_args
config: example_config/MIMIC-50/caml_tune.yml
cpu: false
data_workers: 4
eval: false
label_file: null
metric_threshold: 0.5
result_dir: runs
silent: true
test_path: data/MIMIC-50/test.txt
train_path: data/MIMIC-50/train.txt
val_path: null
val_size: 0.2